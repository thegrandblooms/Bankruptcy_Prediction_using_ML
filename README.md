![Bankruptcy Header](https://github.com/thegrandblooms/dsc-phase-3-project/blob/b7046b303342de6699e35c9a76e1a2f39df47528/graphics/DALL%C2%B7E-2022-07-04-21.jpg)
# Bankruptcy Prediction

## Overview

The goal of this project was to create a predictive model to interpret 95 different features of financial data from the Taiwan stock exchange to determine which companies were most likely to be financially insolvent. The resulting XGBoost model performed with 98.5% accuracy on unseen test data.

Additional features of this notebook include balancing data with a significant class imbalance using SMOTE oversampling, and hyperparameter tuning with cross-validation.

## Business Problem

Bankruptcy has tons of business implications, and better predicting bankruptcy can inform company partnerships, investments, and strategy. From Wikipedia, "Bankruptcy is a legal process through which people or other entities who cannot repay debts to creditors may seek relief from some or all of their debts." By identifying markers of bankrupt companies, we may be able to

## Data

Our data consists of 6819 rows and 96 columns of financial indicators from the Taiwan Stock Exchange, cleaned and provided by the Taiwan Economic Journal. Our data spans from 1999 to 2009, and is provided cleaned and normalized in entirely numeric columns. Our data has a heavy class-imbalance, with only about 3% of the data representing our prediction target of bankrupt companies.

## Methods

To build our predictive model, we do a stratified train-test split and upsample the training set using SMOTE. Then fit Logistic, XGBoost, and Random Forest models to the training data. These baselines are then iteratively improved upon using grid or random searches to tune hyperparameters and find best performing combinations.

## Validation

For model validation, much of the analysis was built around F1 scores, since accuracy is not a good measure of performance for class-imbalanced data. If we simply said every company was not bankrupt, we would have a 96.8% accurate model, since only 3.2% of companies in the dataset are bankrupt. F1 scores measure how well we can predict our target, ignoring class imbalance.

![Papers on the moon, generated by DALL-E](https://github.com/thegrandblooms/dsc-phase-3-project/blob/b7046b303342de6699e35c9a76e1a2f39df47528/graphics/DALL%C2%B7E%202022-07-04%2021.35.34%20-%20An%20award%20winning%20black%20and%20white%20journalistic%20photograph%20of%20stacks%20and%20stacks%20of%20paper%20on%20a%20lunar%20landscape%20from%20the%20first%20moon%20mission.png)

## Findings

Logistic Regression creates Inclusive predictions: 
Marks ~80% of bankrupt companies in unseen data; marks represent about a *1 in 5 chance of bankruptcy. Useful for early warnings.

XGBoost creates Precise predictions: 
Marks ~50% of bankrupt companies in unseen data; marks represent about a *50/50 chance of bankruptcy. Useful for second-stage confirmation. Accuracy of 98.6%.

- Financial data can now be fed to our model to score organizations for solvency and identify complex risks that might be missed by humans.
- Different budgeting plans could be scored by feeding in predicted financial data and assessing model confidence.
- Early identification of affordable assets or IP, identifying and consulting at-risk companies, avoiding dangerous partnerships

## Conclusions

The biggest business recommendations from this were to use Logistic Regression to flag companies, and to use XGBoost for a confident confirmation. Our logistic Regression model found 80% of the bankrupt companies, but had many false positives. XGBoost was very precise, but missed about 50% of bankrupt targets.

Bankruptcy is not entirely predicted by numbers. We can make estimations that are a lot better than chance, but bankruptcy was not 100% correlated with the available financial data.

## Next Steps

- More data about the data
Is the financial data from the same time as the bankruptcy label? Can we identify where the noise or discrepancy is coming from? Is it a consequence of the way the data was processed before our analysis?

- More Feature Engineering
Are a high number of features reducing the accuracy of our models?

- More Access to Raw Data
There may be more information which could be recovered.

## For more information

See the full analysis in the Jupyter Notebook or review the presentation in the pdf.

For additional information, contact Blake McMeekin at blakemcme@gmail.com

## Repository Structure
```
├── Bankruptcy_Detection
│   └── data.csv
├── graphics
├── Phase 3 Project - Bankruptcy Prediction.pdf
├── README.md
└── Bankruptcy Prediction.ipynb
```
